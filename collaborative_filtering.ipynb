{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMojAQs4tLHKCO5ssECewJ+",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hyeonsang010716/Recommendation-system/blob/main/collaborative_filtering.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y86-eR8HqqkI",
        "outputId": "d7477c64-5273-4127-d43c-5f704f187317"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2024-03-28 04:53:29--  https://files.grouplens.org/datasets/movielens/ml-25m.zip\n",
            "Resolving files.grouplens.org (files.grouplens.org)... 128.101.65.152\n",
            "Connecting to files.grouplens.org (files.grouplens.org)|128.101.65.152|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 261978986 (250M) [application/zip]\n",
            "Saving to: ‘ml-25m.zip’\n",
            "\n",
            "ml-25m.zip          100%[===================>] 249.84M  78.2MB/s    in 3.2s    \n",
            "\n",
            "2024-03-28 04:53:32 (78.2 MB/s) - ‘ml-25m.zip’ saved [261978986/261978986]\n",
            "\n",
            "Archive:  ml-25m.zip\n",
            "   creating: ml-25m/\n",
            "  inflating: ml-25m/tags.csv         \n",
            "  inflating: ml-25m/links.csv        \n",
            "  inflating: ml-25m/README.txt       \n",
            "  inflating: ml-25m/ratings.csv      \n",
            "  inflating: ml-25m/genome-tags.csv  \n",
            "  inflating: ml-25m/genome-scores.csv  \n",
            "  inflating: ml-25m/movies.csv       \n"
          ]
        }
      ],
      "source": [
        "!wget https://files.grouplens.org/datasets/movielens/ml-25m.zip\n",
        "!unzip ml-25m.zip"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "users = []\n",
        "items = []\n",
        "ratings = []\n",
        "\n",
        "with open(\"ml-25m/ratings.csv\") as f:\n",
        "  print(f.readline())\n",
        "  for line in f:\n",
        "    uid , mid , rating , _ = line.split(\",\")\n",
        "    users.append(int(uid))\n",
        "    items.append(int(mid))\n",
        "    ratings.append(float(rating))\n",
        "users = np.array(users)\n",
        "items = np.array(items)\n",
        "ratings = np.array(ratings)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GOWElR_fq3ex",
        "outputId": "5e1ca896-4be0-44d9-9d08-61a67480de74"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "userId,movieId,rating,timestamp\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#기본 RMSE\n",
        "\n",
        "m = ratings.mean()\n",
        "RMSE = ((ratings - m) ** 2).mean() ** 0.5\n",
        "RMSE"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NLX1dhGnu4Yq",
        "outputId": "6186ad54-295f-4324-a9fc-7845a42f807c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1.0607439399275531"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "user_bias = np.zeros(users.max() + 1)\n",
        "item_bias = np.zeros(items.max() + 1)\n",
        "alpha = ratings.mean()\n",
        "\n"
      ],
      "metadata": {
        "id": "NuSWa_vywHrB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lr = 1\n",
        "lmd = 0.001\n",
        "\n",
        "n_ratings = len(ratings)\n",
        "n_users = len(user_bias)\n",
        "n_items = len(item_bias)\n",
        "\n",
        "for epoch in range(20):\n",
        "  h = alpha + user_bias[users] + item_bias[items]\n",
        "  diff = h - ratings\n",
        "  rmse = (diff ** 2).mean() ** 0.5\n",
        "  print(\"epoch : {} , rmse : {}\".format(epoch , rmse))\n",
        "  grd_alpha = diff.mean()\n",
        "  grd_user_bias = np.bincount(users , weights = diff) / n_ratings + lmd * user_bias\n",
        "  grd_item_bias = np.bincount(items , weights = diff) / n_ratings + lmd * item_bias\n",
        "  alpha = alpha - lr * grd_alpha\n",
        "  user_bias = user_bias - lr * grd_user_bias\n",
        "  item_bias = item_bias - lr * grd_item_bias\n",
        "\n",
        "rmse = (diff ** 2).mean() ** 0.5\n",
        "print(\"epoch : {} , rmse : {}\".format(epoch , rmse))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3N4fnj-Xa5uO",
        "outputId": "9f1b3dda-6fdf-4f11-c9dd-7976346a271b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch : 0 , rmse : 1.0607439399275531\n",
            "epoch : 1 , rmse : 1.0606227041512328\n",
            "epoch : 2 , rmse : 1.0605019292889002\n",
            "epoch : 3 , rmse : 1.060381604488675\n",
            "epoch : 4 , rmse : 1.0602617275043111\n",
            "epoch : 5 , rmse : 1.0601422961027653\n",
            "epoch : 6 , rmse : 1.0600233080641188\n",
            "epoch : 7 , rmse : 1.0599047611814914\n",
            "epoch : 8 , rmse : 1.0597866532609672\n",
            "epoch : 9 , rmse : 1.059668982121504\n",
            "epoch : 10 , rmse : 1.0595517455948595\n",
            "epoch : 11 , rmse : 1.0594349415254984\n",
            "epoch : 12 , rmse : 1.0593185677705277\n",
            "epoch : 13 , rmse : 1.0592026221996016\n",
            "epoch : 14 , rmse : 1.0590871026948503\n",
            "epoch : 15 , rmse : 1.058972007150802\n",
            "epoch : 16 , rmse : 1.0588573334742943\n",
            "epoch : 17 , rmse : 1.0587430795844113\n",
            "epoch : 18 , rmse : 1.0586292434123923\n",
            "epoch : 19 , rmse : 1.0585158229015668\n",
            "epoch : 19 , rmse : 1.0585158229015668\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "ratings_tensor = torch.from_numpy(ratings)\n",
        "alpha = torch.tensor(ratings.mean() , requires_grad = True)\n",
        "user_bias = torch.zeros(users.max() + 1 , requires_grad = True)\n",
        "item_bias = torch.zeros(items.max() + 1 , requires_grad = True)\n",
        "lmd = 0.001\n",
        "optim = torch.optim.SGD([alpha , user_bias , item_bias] , lr = 1 )\n",
        "\n",
        "for epoch in range(20):\n",
        "  h = alpha + user_bias[users] + item_bias[items]\n",
        "  mse = ((h - ratings_tensor) ** 2).mean()\n",
        "  reg = lmd * (((user_bias) ** 2).mean() + (item_bias ** 2).mean())\n",
        "  cost = mse + reg\n",
        "  optim.zero_grad()\n",
        "  cost.backward()\n",
        "  optim.step()\n",
        "\n",
        "  with torch.no_grad():\n",
        "    rmse = ((h - ratings_tensor) ** 2).mean() ** 0.5\n",
        "    print(\"epoch : {} , rmse : {} \".format(epoch , rmse))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kzFHxBHmf_b4",
        "outputId": "79a10634-9afb-4e77-b7ed-d3578e624a49"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch : 0 , rmse : 1.0607439399275533 \n",
            "epoch : 1 , rmse : 1.0605016242212497 \n",
            "epoch : 2 , rmse : 1.0602606413495452 \n",
            "epoch : 3 , rmse : 1.0600209894996253 \n",
            "epoch : 4 , rmse : 1.05978263276361 \n",
            "epoch : 5 , rmse : 1.059545571873008 \n",
            "epoch : 6 , rmse : 1.0593097959363704 \n",
            "epoch : 7 , rmse : 1.0590752792200044 \n",
            "epoch : 8 , rmse : 1.0588420273709978 \n",
            "epoch : 9 , rmse : 1.058610017432027 \n",
            "epoch : 10 , rmse : 1.0583792505466205 \n",
            "epoch : 11 , rmse : 1.058149716351938 \n",
            "epoch : 12 , rmse : 1.0579214030635105 \n",
            "epoch : 13 , rmse : 1.0576943162900916 \n",
            "epoch : 14 , rmse : 1.057468431092836 \n",
            "epoch : 15 , rmse : 1.057243734949861 \n",
            "epoch : 16 , rmse : 1.0570202218734992 \n",
            "epoch : 17 , rmse : 1.0567978761373642 \n",
            "epoch : 18 , rmse : 1.0565766983487688 \n",
            "epoch : 19 , rmse : 1.0563566787566905 \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "lmd = 0.001\n",
        "\n",
        "user_bias = np.zeros(users.max() + 1)\n",
        "item_bias = np.zeros(items.max() + 1)\n",
        "alpha = ratings.mean()\n",
        "for epoch in range(10):\n",
        "  h = alpha + user_bias[users] + item_bias[items]\n",
        "  rmse = ((h - ratings) ** 2).mean() ** 0.5\n",
        "  print(\"epoch : {} , rmse : {}\".format(epoch , rmse))\n",
        "  alpha = (ratings - (user_bias[users] + item_bias[items])).mean()\n",
        "  user_bias = np.bincount(users , weights = ratings - (alpha + item_bias[items])) / (np.bincount(users) + lmd)\n",
        "  item_bias = np.bincount(items , weights = ratings - (alpha + user_bias[users])) / (np.bincount(items) + lmd)\n",
        "\n",
        "print(\"final rmse : {}\".format(rmse))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O3FJARa3jGhl",
        "outputId": "9af88963-2623-4b88-ddab-5416ba219dfa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch : 0 , rmse : 1.0607439399275531\n",
            "epoch : 1 , rmse : 0.8663159834756426\n",
            "epoch : 2 , rmse : 0.8510867185839471\n",
            "epoch : 3 , rmse : 0.8503568292676987\n",
            "epoch : 4 , rmse : 0.8503078899843288\n",
            "epoch : 5 , rmse : 0.8503025377563744\n",
            "epoch : 6 , rmse : 0.8503016450633218\n",
            "epoch : 7 , rmse : 0.8503014646716495\n",
            "epoch : 8 , rmse : 0.8503014258804191\n",
            "epoch : 9 , rmse : 0.8503014173907169\n",
            "final rmse : 0.8503014173907169\n"
          ]
        }
      ]
    }
  ]
}